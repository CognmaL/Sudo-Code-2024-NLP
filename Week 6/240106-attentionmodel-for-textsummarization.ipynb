{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T15:21:11.987492Z","iopub.status.busy":"2024-10-19T15:21:11.986844Z"},"trusted":true},"outputs":[],"source":["!pip install transformers evaluate datasets rouge_score -q"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T05:01:18.765744Z","iopub.status.busy":"2024-10-19T05:01:18.765343Z","iopub.status.idle":"2024-10-19T05:01:41.469402Z","shell.execute_reply":"2024-10-19T05:01:41.468433Z","shell.execute_reply.started":"2024-10-19T05:01:18.765699Z"},"trusted":true},"outputs":[],"source":["# Import essential libraries\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import warnings\n","from datasets import Dataset\n","from transformers import (\n","    TFAutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n",")\n","import evaluate"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:31:25.735877Z","iopub.status.busy":"2024-10-19T06:31:25.735036Z","iopub.status.idle":"2024-10-19T06:31:30.318596Z","shell.execute_reply":"2024-10-19T06:31:30.317617Z","shell.execute_reply.started":"2024-10-19T06:31:25.735835Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMBartForConditionalGeneration.\n","\n","Some layers of TFMBartForConditionalGeneration were not initialized from the model checkpoint at vinai/bartpho-word and are newly initialized: ['final_logits_bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Configuration\n","num_workers = os.cpu_count()\n","epochs = 7\n","learning_rate = 2e-5\n","\n","# Model \n","model_name = 'vinai/bartpho-word'  \n","\n","# Warnings configuration\n","warnings.filterwarnings('ignore')\n","\n","# Load the model and tokenizer (TensorFlow version)\n","model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T05:38:03.563781Z","iopub.status.busy":"2024-10-19T05:38:03.563142Z","iopub.status.idle":"2024-10-19T05:48:33.871683Z","shell.execute_reply":"2024-10-19T05:48:33.870730Z","shell.execute_reply.started":"2024-10-19T05:38:03.563743Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01828f6f057346c49fb2f298454b6321","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/105418 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2acbb0e7f98841a6956d36dfdf9abfea","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/22642 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6850de2ac13048afa467e196e35cfa91","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/22644 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["out_dir = '/kaggle/working'  # Output directory\n","train_path = '/kaggle/input/vietnews-dataset/train.csv'  # Path to training data\n","valid_path = '/kaggle/input/vietnews-dataset/valid.csv'  # Path to validation data\n","test_path = '/kaggle/input/vietnews-dataset/test.csv'  # Path to test data\n","\n","# Convert datasets to Hugging Face format after cleaning\n","train_df[\"Content\"] = train_df[\"Content\"].astype(str)\n","valid_df[\"Content\"] = valid_df[\"Content\"].astype(str)\n","test_df[\"Content\"] = test_df[\"Content\"].astype(str)\n","train_df[\"Abstract\"] = train_df[\"Abstract\"].astype(str)\n","valid_df[\"Abstract\"] = valid_df[\"Abstract\"].astype(str)\n","test_df[\"Abstract\"] = test_df[\"Abstract\"].astype(str)\n","\n","train_ds = Dataset.from_pandas(train_df)\n","valid_ds = Dataset.from_pandas(valid_df)\n","test_ds = Dataset.from_pandas(test_df)\n","\n","# Preprocess function to tokenize Vietnamese inputs and outputs\n","def preprocessing(examples):\n","    \"\"\"\n","    Tokenizes the input Vietnamese text (Content) and prepares the model inputs for training.\n","    Uses the tokenizer's maximum length to handle longer documents.\n","    \"\"\"\n","    inputs = [doc for doc in examples[\"Content\"]]\n","    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n","    \n","    # Tokenizing Abstracts (targets)\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"Abstract\"], max_length=1024, truncation=True, padding=\"max_length\")\n","    \n","    # Adding labels to the inputs\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","# Tokenizing the Vietnamese datasets\n","tokenized_train = train_ds.map(preprocessing, batched=True)\n","tokenized_valid = valid_ds.map(preprocessing, batched=True)\n","tokenized_test = test_ds.map(preprocessing, batched=True)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:33:52.481574Z","iopub.status.busy":"2024-10-19T06:33:52.481060Z","iopub.status.idle":"2024-10-19T06:33:52.488305Z","shell.execute_reply":"2024-10-19T06:33:52.487368Z","shell.execute_reply.started":"2024-10-19T06:33:52.481523Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['Filename', 'Title', 'Abstract', 'Content', 'Keyword', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 105418\n","})"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_train"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:36:06.843688Z","iopub.status.busy":"2024-10-19T06:36:06.842865Z","iopub.status.idle":"2024-10-19T06:36:07.796848Z","shell.execute_reply":"2024-10-19T06:36:07.795905Z","shell.execute_reply.started":"2024-10-19T06:36:06.843648Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input IDs shape: (16, 1024)\n","Attention Mask shape: (16, 1024)\n","Labels shape: (16, 1024)\n"]}],"source":["import tensorflow as tf\n","\n","# Convert the dataset to a TensorFlow dataset\n","tf_train_dataset = tokenized_train.to_tf_dataset(\n","    columns=['input_ids', 'attention_mask'],  # Input features\n","    label_cols='labels',                      # Label column\n","    shuffle=True,\n","    batch_size=16,\n","    collate_fn=lambda x: {\n","        'input_ids': tf.ragged.constant([i['input_ids'] for i in x], dtype=tf.int32).to_tensor(),\n","        'attention_mask': tf.ragged.constant([i['attention_mask'] for i in x], dtype=tf.int32).to_tensor(),\n","        'labels': tf.constant([i['labels'] for i in x], dtype=tf.int32)\n","    }\n",")\n","\n","tf_valid_dataset = tokenized_valid.to_tf_dataset(\n","    columns=['input_ids', 'attention_mask'],  # Input features\n","    label_cols='labels',                      # Label column\n","    shuffle=True,\n","    batch_size=16,\n","    collate_fn=lambda x: {\n","        'input_ids': tf.ragged.constant([i['input_ids'] for i in x], dtype=tf.int32).to_tensor(),\n","        'attention_mask': tf.ragged.constant([i['attention_mask'] for i in x], dtype=tf.int32).to_tensor(),\n","        'labels': tf.constant([i['labels'] for i in x], dtype=tf.int32)\n","    }\n",")\n","\n","# Verify a batch\n","for batch in tf_train_dataset.take(1):\n","    inputs, labels = batch\n","    print(\"Input IDs shape:\", inputs['input_ids'].shape)\n","    print(\"Attention Mask shape:\", inputs['attention_mask'].shape)\n","    print(\"Labels shape:\", labels.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T15:19:02.183700Z","iopub.status.busy":"2024-10-19T15:19:02.183425Z","iopub.status.idle":"2024-10-19T15:19:02.508430Z","shell.execute_reply":"2024-10-19T15:19:02.507287Z","shell.execute_reply.started":"2024-10-19T15:19:02.183668Z"},"trusted":true},"outputs":[],"source":["max_len = 512\n","\n","# Giảm kích thước dữ liệu trong tập huấn luyện\n","tf_train_dataset = tf_train_dataset.map(lambda x, y: ({\n","    'input_ids': x['input_ids'][:, :max_len],  # Chỉ lấy 512 token đầu tiên\n","    'attention_mask': x['attention_mask'][:, :max_len]\n","}, y[:, :max_len]))  \n","model.fit(tf_train_dataset.batch(32), epochs=3)\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:48:18.905303Z","iopub.status.busy":"2024-10-19T06:48:18.904532Z","iopub.status.idle":"2024-10-19T06:48:18.978308Z","shell.execute_reply":"2024-10-19T06:48:18.977449Z","shell.execute_reply.started":"2024-10-19T06:48:18.905261Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"tfm_bart_for_conditional_generation_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," model (TFMBartMainLayer)    multiple                  420361216 \n","                                                                 \n"," final_logits_bias (BiasLay  multiple                  64001     \n"," er)                                                             \n","                                                                 \n","=================================================================\n","Total params: 420425217 (1.57 GB)\n","Trainable params: 420361216 (1.57 GB)\n","Non-trainable params: 64001 (250.00 KB)\n","_________________________________________________________________\n"]}],"source":["# Adjust the batch size to match your TensorFlow dataset\n","batch_size = 16\n","\n","# Calculate steps per epoch and total training steps\n","steps_per_epoch = len(tokenized_train) // batch_size\n","total_training_steps = steps_per_epoch * epochs\n","\n","# Create an optimizer using the transformers utility\n","from transformers import create_optimizer\n","\n","optimizer, schedule = create_optimizer(\n","    init_lr=learning_rate, \n","    num_train_steps=total_training_steps, \n","    num_warmup_steps=0\n",")\n","\n","# Compile the model with the optimizer and loss function\n","model.compile(optimizer=optimizer, loss=model.compute_loss)\n","model.summary()\n","\n","# Train the model\n","model.fit(\n","    tf_train_dataset,\n","    validation_data=tf_valid_dataset,\n","    epochs=epochs\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:02:41.547598Z","iopub.status.busy":"2024-10-19T06:02:41.546850Z","iopub.status.idle":"2024-10-19T06:02:59.919567Z","shell.execute_reply":"2024-10-19T06:02:59.918546Z","shell.execute_reply.started":"2024-10-19T06:02:41.547555Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary 1: Giá vàng sẽ tiếp_tục tăng trong dài hạn, một phần do tình_hình tài_chính bấp_bênh của nhiều quốc_gia phương Tây( * ) : 1 - 1 - 1 - 1 - 1 - 1 - 1\n"]}],"source":["def summarize_text(texts, max_length=150, min_length=40):\n","    \"\"\"\n","    Generate summaries for a list of input texts using the trained model.\n","    \n","    Args:\n","    - texts: List of strings containing the texts to summarize.\n","    - max_length: Maximum length of the summary.\n","    - min_length: Minimum length of the summary.\n","    \n","    Returns:\n","    - List of generated summaries.\n","    \"\"\"\n","    # Tokenize inputs\n","    inputs = tokenizer(texts, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"tf\")\n","    \n","    # Generate summaries\n","    summaries = model.generate(\n","        inputs[\"input_ids\"],\n","        attention_mask=inputs[\"attention_mask\"],\n","        max_length=max_length,\n","        min_length=min_length,\n","        length_penalty=2.0,\n","        num_beams=4,\n","        early_stopping=True\n","    )\n","    \n","    # Decode summaries\n","    return [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in summaries]\n","\n","# Example usage:\n","input_texts = [\n","    \"Giá vàng sẽ tiếp tục tăng trong dài hạn, một phần do tình hình tài chính bấp bênh của nhiều quốc gia phương Tây. Hiệp hội Thị trường Vàng London (LBMA) dự đoán, giá vàng có thể tăng lên 2.941 USD/ounce trong 12 tháng tới.\"\n","]\n","\n","summarized_texts = summarize_text(input_texts)\n","for i, summary in enumerate(summarized_texts):\n","    print(f\"Summary {i+1}: {summary}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["----"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5791076,"sourceId":9513260,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
